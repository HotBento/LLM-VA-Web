<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM-VA: Resolving the Jailbreak-Overrefusal Trade-off via Vector Alignment</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f8f9fa;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 60px 20px;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        h1 {
            font-size: 2.5em;
            margin-bottom: 20px;
            font-weight: 700;
        }

        .subtitle {
            font-size: 1.2em;
            margin-bottom: 30px;
            opacity: 0.95;
        }

        .authors {
            margin-top: 30px;
            font-size: 1.1em;
        }

        .affiliation {
            margin-top: 15px;
            font-size: 0.95em;
            opacity: 0.9;
        }

        .buttons {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-top: 30px;
            flex-wrap: wrap;
        }

        .btn {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 12px 25px;
            background-color: white;
            color: #667eea;
            text-decoration: none;
            border-radius: 25px;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
            background-color: #f8f9fa;
        }

        .btn i {
            font-size: 1.1em;
        }

        .section {
            background: white;
            margin: 30px 0;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }

        h2 {
            color: #667eea;
            margin-bottom: 20px;
            font-size: 2em;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }

        h3 {
            color: #764ba2;
            margin-top: 25px;
            margin-bottom: 15px;
            font-size: 1.4em;
        }

        .abstract {
            text-align: justify;
            line-height: 1.8;
            font-size: 1.05em;
        }

        .method-overview {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }

        .method-card {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 25px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .method-card h4 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 1.2em;
        }

        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }

        .result-card {
            text-align: center;
            padding: 30px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }

        .result-number {
            font-size: 3em;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .result-label {
            font-size: 1em;
            opacity: 0.95;
        }

        .figure-container {
            text-align: center;
            margin: 30px 0;
        }

        .figure-container img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }

        .figure-caption {
            margin-top: 15px;
            font-style: italic;
            color: #666;
        }

        ul, ol {
            margin-left: 30px;
            margin-top: 15px;
        }

        li {
            margin-bottom: 10px;
        }

        .bibtex {
            background: #f5f5f5;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            overflow-x: auto;
        }

        footer {
            text-align: center;
            padding: 30px;
            color: #666;
            margin-top: 50px;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.8em;
            }

            .buttons {
                flex-direction: column;
            }

            .section {
                padding: 25px;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>LLM-VA: Resolving the Jailbreak-Overrefusal Trade-off via Vector Alignment</h1>
            <div class="authors">
                Anonymous Authors
            </div>
            <div class="affiliation">
                Under Review
            </div>
            <div class="buttons">
                <a href="https://anonymous.4open.science/r/LLM-VA-748D/pdf/LLM-VA.pdf" class="btn" target="_blank">
                    <i class="fas fa-file-pdf"></i> Paper
                </a>
                <a href="https://anonymous.4open.science/r/LLM-VA-748D/" class="btn" target="_blank">
                    <i class="fab fa-github"></i> Code
                </a>
                <a href="https://figshare.com/s/f2aa365c87a80097a436" class="btn" target="_blank">
                    <i class="fas fa-database"></i> Models
                </a>
            </div>
        </div>
    </header>

    <div class="container">
        <section class="section">
            <h2><i class="fas fa-book"></i> Abstract</h2>
            <p class="abstract">
                Safety-aligned LLMs suffer from two failure modes: <strong>jailbreak</strong> (responding to harmful inputs) and 
                <strong>over-refusal</strong> (declining benign queries). Existing vector steering methods adjust the magnitude 
                of answer vectors, but this creates a fundamental trade-off—reducing jailbreak increases over-refusal and vice versa. 
                We identify the root cause: LLMs encode the decision to respond (answer vector <em>v<sub>a</sub></em>) and the judgment 
                of input safety (benign vector <em>v<sub>b</sub></em>) as nearly orthogonal directions, treating them as independent processes.
            </p>
            <p class="abstract" style="margin-top: 15px;">
                We propose <strong>LLM-VA</strong>, which aligns <em>v<sub>a</sub></em> with <em>v<sub>b</sub></em> through closed-form 
                weight updates, making the model's willingness to respond causally dependent on its safety assessment—without fine-tuning 
                or architectural changes. Our method identifies vectors at each layer using SVMs, selects safety-relevant layers, and 
                iteratively aligns vectors via minimum-norm weight modifications.
            </p>
            <p class="abstract" style="margin-top: 15px;">
                Experiments on <strong>12 LLMs</strong> demonstrate that LLM-VA achieves <strong>11.45% higher F1</strong> than the best 
                baseline while preserving <strong>95.92% utility</strong>, and automatically adapts to each model's safety bias without manual tuning.
            </p>
            
            <div class="figure-container">
                <object data="static/framework.svg" type="image/svg+xml" style="width: 100%; height: auto; max-width: 900px;"></object>
                <p class="figure-caption">Figure 1: Overall framework of LLM-VA. The method aligns the answer vector v<sub>a</sub> with the benign vector v<sub>b</sub> through three main steps: (1) vector identification via SVMs, (2) layer selection, and (3) vector alignment via weight updates.</p>
            </div>
        </section>

        <section class="section">
            <h2><i class="fas fa-chart-line"></i> Key Results</h2>
            <div class="results-grid">
                <div class="result-card">
                    <div class="result-number">+11.45%</div>
                    <div class="result-label">F1 Improvement over Best Baseline</div>
                </div>
                <div class="result-card">
                    <div class="result-number">95.92%</div>
                    <div class="result-label">Utility Preservation</div>
                </div>
                <div class="result-card">
                    <div class="result-number">12</div>
                    <div class="result-label">LLMs Evaluated</div>
                </div>
                <div class="result-card">
                    <div class="result-number">8/12</div>
                    <div class="result-label">Models Achieving Best F1</div>
                </div>
            </div>
        </section>

        <section class="section">
            <h2><i class="fas fa-lightbulb"></i> Method Overview</h2>
            <p>LLM-VA consists of three main steps:</p>
            
            <div class="method-overview">
                <div class="method-card">
                    <h4>1. Vector Identification via SVMs</h4>
                    <p>Train SVMs at each layer to find hyperplanes separating benign/toxic and answer/refuse samples, yielding both v<sub>b</sub> and v<sub>a</sub>.</p>
                </div>
                <div class="method-card">
                    <h4>2. Layer Selection</h4>
                    <p>Identify layers most relevant to safety decisions based on their contribution to final output and SVM classification accuracy.</p>
                </div>
                <div class="method-card">
                    <h4>3. Vector Alignment</h4>
                    <p>Adjust layer weights to align v<sub>a</sub> with v<sub>b</sub>, ensuring benign inputs activate the "answer" direction while toxic inputs do not.</p>
                </div>
            </div>
        </section>

        <section class="section">
            <h2><i class="fas fa-key"></i> Key Findings</h2>
            
            <h3>The Root Cause: Near-Orthogonality</h3>
            <p>We discover that LLMs encode response decisions (v<sub>a</sub>) and safety assessments (v<sub>b</sub>) as nearly orthogonal directions (~90°), revealing that they treat these as independent processes. This explains both failure modes: the model may answer toxic inputs (jailbreak) or refuse benign ones (over-refusal).</p>

            <h3>Adaptive Behavior</h3>
            <p>LLM-VA automatically adapts to each model's initial safety bias:</p>
            <ul>
                <li>For models with high ASR but low ORR (e.g., Mistral-v0.3-7B: 81% ASR, 29% ORR), LLM-VA primarily reduces ASR to ensure safety</li>
                <li>For models with low ASR but high ORR (e.g., Llama-3.1-8B: 7% ASR, 53% ORR), it primarily decreases ORR to enhance usability</li>
                <li>This adaptive behavior emerges naturally without manual hyperparameter tuning</li>
            </ul>

            <h3>Comprehensive Evaluation</h3>
            <p>Evaluated on 12 widely-used instruction-tuned LLMs:</p>
            <ul>
                <li>Llama-3.1 (8B), gemma-2 (9B), Mistral-v0.3 (7B)</li>
                <li>Phi-3.5 (4B), Phi-4 (4B, 15B)</li>
                <li>Qwen2.5 (3B, 7B, 14B), Qwen3 (4B, 8B, 14B)</li>
            </ul>
        </section>

        <section class="section">
            <h2><i class="fas fa-balance-scale"></i> Advantages Over Existing Methods</h2>
            <ul>
                <li><strong>No Fine-tuning Required:</strong> Achieves alignment through closed-form weight updates</li>
                <li><strong>No Architectural Changes:</strong> Works with standard model architectures</li>
                <li><strong>Addresses Both Failure Modes:</strong> Simultaneously reduces jailbreak and over-refusal</li>
                <li><strong>Automatic Adaptation:</strong> No manual hyperparameter tuning needed for different models</li>
                <li><strong>High Utility Preservation:</strong> Maintains 95.92% of original model capabilities</li>
            </ul>
        </section>

        <section class="section">
            <h2><i class="fas fa-quote-left"></i> Citation</h2>
            <p>If you find our work useful, please cite:</p>
            <pre class="bibtex">
@article{llmva2026,
  title={LLM-VA: Resolving the Jailbreak-Overrefusal Trade-off via Vector Alignment},
  author={Anonymous},
  journal={Under Review},
  year={2026}
}
            </pre>
        </section>

        <section class="section">
            <h2><i class="fas fa-envelope"></i> Contact</h2>
            <p>For questions or collaboration opportunities, please reach out through the anonymous repository.</p>
        </section>
    </div>

    <footer>
        <p>&copy; 2026 LLM-VA Project. All rights reserved.</p>
        <p style="margin-top: 10px; font-size: 0.9em;">
            <i class="fas fa-shield-alt"></i> This work is under peer review. Details will be updated upon publication.
        </p>
    </footer>
</body>
</html>
